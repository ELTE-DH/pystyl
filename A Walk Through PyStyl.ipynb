{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Walk through PyStyl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments in stylometry typically kick off with creating a corpus, or the collection of texts which we would like to compare. In pystyl, we use the Corpus class to represent such a text collection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pystyl.corpus import Corpus # lowercase!\n",
    "corpus = Corpus(language='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying a language such as `'en'` (English) is optional. Adding texts from a directory to the corpus is easy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding texts from: /Users/mike/GitRepos/pystyl/data/dummy\n"
     ]
    }
   ],
   "source": [
    "corpus.add_directory(directory='data/dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this function assumes that all texts under this directory have been encoded in UTF-8 and that they have a `.txt` extension. Additionally, the syntax of the filename should be `<category>_<title>.txt`, where category is a label indicates e.g. a text's authorship, genre or date of composition. In our case, this directory looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne_Grey.txt            Charlotte_Professor.txt  Emily_Wuthering.txt\r\n",
      "Anne_Tenant.txt          Charlotte_Shirley.txt\r\n",
      "Charlotte_Eyre.txt       Charlotte_Villette.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls data/dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our corpus currently holds these 7 texts in their raw form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Corpus(7 texts)> \n",
      "Untokenized texts:\n",
      "\n",
      "\t- Grey\t(cat: Anne):\tu'\\ufeffCHAPTER I\\u2014THE PARSONAGE\\n<BOUN'[...]\n",
      "\t- Tenant\t(cat: Anne):\tu'\\ufeffCHAPTER I\\n<BOUNDARY>\\nYou must'[...]\n",
      "\t- Eyre\t(cat: Charlotte):\tu'CHAPTER I\\n<BOUNDARY>\\nThere was'[...]\n",
      "\t- Professor\t(cat: Charlotte):\tu'CHAPTER I. INTRODUCTORY.\\n<BOUN'[...]\n",
      "\t- Shirley\t(cat: Charlotte):\tu'\\ufeffCHAPTER I.\\n<BOUNDARY>\\nLEVITIC'[...]\n",
      "\t- Villette\t(cat: Charlotte):\tu'CHAPTER I.\\n<BOUNDARY>\\nBRETTON.'[...]\n",
      "\t- Wuthering\t(cat: Emily):\tu'<BOUNDARY>\\nCHAPTER I\\n<BOUNDARY'[...]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stylometry, it typical to preprocess your corpus and remove, let's say, punctuation and lowercase texts. In pystyl, we achieve this via the `preprocess()` method, where the `alpha_only` parameter controls whether we only wish to keep alphabetic symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Corpus(7 texts)> \n",
      "Untokenized texts:\n",
      "\n",
      "\t- Grey\t(cat: Anne):\tu'chapter ithe parsonage\\nboundar'[...]\n",
      "\t- Tenant\t(cat: Anne):\tu'chapter i\\nboundary\\nyou must go'[...]\n",
      "\t- Eyre\t(cat: Charlotte):\tu'chapter i\\nboundary\\nthere was n'[...]\n",
      "\t- Professor\t(cat: Charlotte):\tu'chapter i introductory\\nboundar'[...]\n",
      "\t- Shirley\t(cat: Charlotte):\tu'chapter i\\nboundary\\nlevitical\\nb'[...]\n",
      "\t- Villette\t(cat: Charlotte):\tu'chapter i\\nboundary\\nbretton\\nbou'[...]\n",
      "\t- Wuthering\t(cat: Emily):\tu'boundary\\nchapter i\\nboundary\\ni '[...]\n"
     ]
    }
   ],
   "source": [
    "corpus.preprocess(alpha_only=True, lowercase=True)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the corpus is ready to be tokenized, which is helpful if we want to start counting words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Corpus(7 texts)> \n",
      "Tokenized texts:\n",
      "\t- Grey\t(cat: Anne):\tu'chapter ithe parsonage boundary all true histories contain instruction though'[...]\n",
      "\t- Tenant\t(cat: Anne):\tu'chapter i boundary you must go back with me to'[...]\n",
      "\t- Eyre\t(cat: Charlotte):\tu'chapter i boundary there was no possibility of taking a'[...]\n",
      "\t- Professor\t(cat: Charlotte):\tu'chapter i introductory boundary the other day in looking over'[...]\n",
      "\t- Shirley\t(cat: Charlotte):\tu'chapter i boundary levitical boundary of late years an abundant'[...]\n",
      "\t- Villette\t(cat: Charlotte):\tu'chapter i boundary bretton boundary my godmother lived in a'[...]\n",
      "\t- Wuthering\t(cat: Emily):\tu'boundary chapter i boundary i have just returned from a'[...]\n"
     ]
    }
   ],
   "source": [
    "corpus.tokenize()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus now holds our texts in a tokenized form. Of course, the novels wildly vary in length. If we would like to split these into shorter segments of e.g. 10,000 words, we can use the `segment()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Corpus(48 texts)> \n",
      "Tokenized texts:\n",
      "\t- Grey_1\t(cat: Anne):\tu'chapter ithe parsonage boundary all true histories contain instruction though'[...]\n",
      "\t- Grey_2\t(cat: Anne):\tu'or neglected to perform her promise and doubting whether to'[...]\n",
      "\t- Grey_3\t(cat: Anne):\tu'was so terribly afraid of papa seeing him boundary has'[...]\n",
      "\t- Tenant_1\t(cat: Anne):\tu'chapter i boundary you must go back with me to'[...]\n",
      "\t- Tenant_2\t(cat: Anne):\tu'and i grew weary of amusing her i felt myself'[...]\n",
      "\t- Tenant_3\t(cat: Anne):\tu'and i returned to my business boundary but i soon'[...]\n",
      "\t- Tenant_4\t(cat: Anne):\tu'lover and ill leave all the sir herberts and valentines'[...]\n",
      "\t- Tenant_5\t(cat: Anne):\tu'shall see come i am in hells torments till you'[...]\n",
      "\t- Tenant_6\t(cat: Anne):\tu'inextricably entangled in the snare of my antagonist boundary check'[...]\n",
      "\t- Tenant_7\t(cat: Anne):\tu'the subject ask mr hargrave boundary at this they simultaneously'[...]\n",
      "\t- Tenant_8\t(cat: Anne):\tu'fingers so marvellously like her own considering he was not'[...]\n",
      "\t- Eyre_1\t(cat: Charlotte):\tu'chapter i boundary there was no possibility of taking a'[...]\n",
      "\t- Eyre_2\t(cat: Charlotte):\tu'had seen miss scatcherd flog her pupil burns i wandered'[...]\n",
      "\t- Eyre_3\t(cat: Charlotte):\tu'left it till within six months ago when she first'[...]\n",
      "\t- Eyre_4\t(cat: Charlotte):\tu'bolt and opened the door with a trembling hand there'[...]\n",
      "\t- Eyre_5\t(cat: Charlotte):\tu'will you stir one step to meet it where it'[...]\n",
      "\t- Eyre_6\t(cat: Charlotte):\tu'my facewhich i feel rebel insolently against my will and'[...]\n",
      "\t- Eyre_7\t(cat: Charlotte):\tu'to be entrapped into a feigned union with a defrauded'[...]\n",
      "\t- Eyre_8\t(cat: Charlotte):\tu'her compassionate gaze with a smile i saidi will trust'[...]\n",
      "\t- Eyre_9\t(cat: Charlotte):\tu'starsevery one lit me to a purpose or delight those'[...]\n",
      "\t- Professor_1\t(cat: Charlotte):\tu'chapter i introductory boundary the other day in looking over'[...]\n",
      "\t- Professor_2\t(cat: Charlotte):\tu'admission into their houses just here however this observation is'[...]\n",
      "\t- Professor_3\t(cat: Charlotte):\tu'as i made the transit of the carre i observed'[...]\n",
      "\t- Professor_4\t(cat: Charlotte):\tu'me as the treacherous spawn of a perfidious country he'[...]\n",
      "\t- Shirley_1\t(cat: Charlotte):\tu'chapter i boundary levitical boundary of late years an abundant'[...]\n",
      "\t- Shirley_2\t(cat: Charlotte):\tu'record of their deeds boundary instead then of harrowing up'[...]\n",
      "\t- Shirley_3\t(cat: Charlotte):\tu'let us return thanks said he which he did forthwith'[...]\n",
      "\t- Shirley_4\t(cat: Charlotte):\tu'to the happiness and welfare of all if each knew'[...]\n",
      "\t- Shirley_5\t(cat: Charlotte):\tu'voice boundary but there are worse things than fairies to'[...]\n",
      "\t- Shirley_6\t(cat: Charlotte):\tu'in firstrate company order and setting out a collation of'[...]\n",
      "\t- Shirley_7\t(cat: Charlotte):\tu'i dare say he thinks he has outwitted me cleverly'[...]\n",
      "\t- Shirley_8\t(cat: Charlotte):\tu'in the garden her eyes longed to see something more'[...]\n",
      "\t- Shirley_9\t(cat: Charlotte):\tu'abode than any briarfield or whinbury owned and what is'[...]\n",
      "\t- Shirley_10\t(cat: Charlotte):\tu'up crimson when she has offered me her hand and'[...]\n",
      "\t- Villette_1\t(cat: Charlotte):\tu'chapter i boundary bretton boundary my godmother lived in a'[...]\n",
      "\t- Villette_2\t(cat: Charlotte):\tu'beclouded sky overhanging all in my reverie methought i saw'[...]\n",
      "\t- Villette_3\t(cat: Charlotte):\tu'than feel the freshness of dew descending the turf was'[...]\n",
      "\t- Villette_4\t(cat: Charlotte):\tu'i say you immensely exaggerate both its quality and quantitywas'[...]\n",
      "\t- Villette_5\t(cat: Charlotte):\tu'what does he think of her boundary cela ne vaut'[...]\n",
      "\t- Villette_6\t(cat: Charlotte):\tu'own lot all that was painful in the destiny of'[...]\n",
      "\t- Villette_7\t(cat: Charlotte):\tu'habitually consumed for her first and second breakfasts beer and'[...]\n",
      "\t- Villette_8\t(cat: Charlotte):\tu'bringing home to him his worst apprehensions astoundingly realized i'[...]\n",
      "\t- Villette_9\t(cat: Charlotte):\tu'less her sleeping fantasies boundary if i dreamt it i'[...]\n",
      "\t- Wuthering_1\t(cat: Emily):\tu'boundary chapter i boundary i have just returned from a'[...]\n",
      "\t- Wuthering_2\t(cat: Emily):\tu'one garret along the roof into the skylight of the'[...]\n",
      "\t- Wuthering_3\t(cat: Emily):\tu'two gardeners youll surely not wait to be thrust into'[...]\n",
      "\t- Wuthering_4\t(cat: Emily):\tu'away ive recovered from my first desire to be killed'[...]\n",
      "\t- Wuthering_5\t(cat: Emily):\tu'running or bounding now though the chill wind might well'[...]\n"
     ]
    }
   ],
   "source": [
    "corpus.segment(segment_size=20000)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In stylometry, it is common to manually remove certain words, such as personal pronouns, which are more strongly tied to narrative perspective than authorial writing style. To remove these from our English texts, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Corpus(48 texts)> \n",
      "Tokenized texts:\n",
      "\t- Grey_1\t(cat: Anne):\tu'chapter ithe parsonage boundary all true histories contain instruction though'[...]\n",
      "\t- Grey_2\t(cat: Anne):\tu'or neglected to perform promise and doubting whether to keep'[...]\n",
      "\t- Grey_3\t(cat: Anne):\tu'was so terribly afraid of papa seeing boundary has been'[...]\n",
      "\t- Tenant_1\t(cat: Anne):\tu'chapter boundary must go back with to the autumn of'[...]\n",
      "\t- Tenant_2\t(cat: Anne):\tu'and grew weary of amusing felt drawn by an irresistible'[...]\n",
      "\t- Tenant_3\t(cat: Anne):\tu'and returned to business boundary but soon began to regret'[...]\n",
      "\t- Tenant_4\t(cat: Anne):\tu'lover and ill leave all the sir herberts and valentines'[...]\n",
      "\t- Tenant_5\t(cat: Anne):\tu'shall see come am in hells torments till speak the'[...]\n",
      "\t- Tenant_6\t(cat: Anne):\tu'inextricably entangled in the snare of antagonist boundary check cried'[...]\n",
      "\t- Tenant_7\t(cat: Anne):\tu'the subject ask mr hargrave boundary at this simultaneously burst'[...]\n",
      "\t- Tenant_8\t(cat: Anne):\tu'fingers so marvellously like own considering was not a woman'[...]\n",
      "\t- Eyre_1\t(cat: Charlotte):\tu'chapter boundary there was no possibility of taking a walk'[...]\n",
      "\t- Eyre_2\t(cat: Charlotte):\tu'had seen miss scatcherd flog pupil burns wandered as usual'[...]\n",
      "\t- Eyre_3\t(cat: Charlotte):\tu'left it till within six months ago when first came'[...]\n",
      "\t- Eyre_4\t(cat: Charlotte):\tu'bolt and opened the door with a trembling hand there'[...]\n",
      "\t- Eyre_5\t(cat: Charlotte):\tu'will stir one step to meet it where it waits'[...]\n",
      "\t- Eyre_6\t(cat: Charlotte):\tu'facewhich feel rebel insolently against will and struggle to express'[...]\n",
      "\t- Eyre_7\t(cat: Charlotte):\tu'to be entrapped into a feigned union with a defrauded'[...]\n",
      "\t- Eyre_8\t(cat: Charlotte):\tu'compassionate gaze with a smile saidi will trust if were'[...]\n",
      "\t- Eyre_9\t(cat: Charlotte):\tu'starsevery one lit to a purpose or delight those who'[...]\n",
      "\t- Professor_1\t(cat: Charlotte):\tu'chapter introductory boundary the other day in looking over papers'[...]\n",
      "\t- Professor_2\t(cat: Charlotte):\tu'admission into houses just here however this observation is not'[...]\n",
      "\t- Professor_3\t(cat: Charlotte):\tu'as made the transit of the carre observed as usual'[...]\n",
      "\t- Professor_4\t(cat: Charlotte):\tu'as the treacherous spawn of a perfidious country in the'[...]\n",
      "\t- Shirley_1\t(cat: Charlotte):\tu'chapter boundary levitical boundary of late years an abundant shower'[...]\n",
      "\t- Shirley_2\t(cat: Charlotte):\tu'record of deeds boundary instead then of harrowing up readers'[...]\n",
      "\t- Shirley_3\t(cat: Charlotte):\tu'let return thanks said which did forthwith and all quitted'[...]\n",
      "\t- Shirley_4\t(cat: Charlotte):\tu'to the happiness and welfare of all if each knew'[...]\n",
      "\t- Shirley_5\t(cat: Charlotte):\tu'voice boundary but there are worse things than fairies to'[...]\n",
      "\t- Shirley_6\t(cat: Charlotte):\tu'in firstrate company order and setting out a collation of'[...]\n",
      "\t- Shirley_7\t(cat: Charlotte):\tu'dare say thinks has outwitted cleverly and this is the'[...]\n",
      "\t- Shirley_8\t(cat: Charlotte):\tu'in the garden eyes longed to see something more than'[...]\n",
      "\t- Shirley_9\t(cat: Charlotte):\tu'abode than any briarfield or whinbury owned and what is'[...]\n",
      "\t- Shirley_10\t(cat: Charlotte):\tu'up crimson when has offered hand and said how do'[...]\n",
      "\t- Villette_1\t(cat: Charlotte):\tu'chapter boundary bretton boundary godmother lived in a handsome house'[...]\n",
      "\t- Villette_2\t(cat: Charlotte):\tu'beclouded sky overhanging all in reverie methought saw the continent'[...]\n",
      "\t- Villette_3\t(cat: Charlotte):\tu'than feel the freshness of dew descending the turf was'[...]\n",
      "\t- Villette_4\t(cat: Charlotte):\tu'say immensely exaggerate both its quality and quantitywas quite abstract'[...]\n",
      "\t- Villette_5\t(cat: Charlotte):\tu'what does think of boundary cela ne vaut rien responded'[...]\n",
      "\t- Villette_6\t(cat: Charlotte):\tu'own lot all that was painful in the destiny of'[...]\n",
      "\t- Villette_7\t(cat: Charlotte):\tu'habitually consumed for first and second breakfasts beer and beef'[...]\n",
      "\t- Villette_8\t(cat: Charlotte):\tu'bringing home to worst apprehensions astoundingly realized could have exulted'[...]\n",
      "\t- Villette_9\t(cat: Charlotte):\tu'less sleeping fantasies boundary if dreamt it saw in dream'[...]\n",
      "\t- Wuthering_1\t(cat: Emily):\tu'boundary chapter boundary have just returned from a visit to'[...]\n",
      "\t- Wuthering_2\t(cat: Emily):\tu'one garret along the roof into the skylight of the'[...]\n",
      "\t- Wuthering_3\t(cat: Emily):\tu'two gardeners youll surely not wait to be thrust into'[...]\n",
      "\t- Wuthering_4\t(cat: Emily):\tu'away ive recovered from first desire to be killed by'[...]\n",
      "\t- Wuthering_5\t(cat: Emily):\tu'running or bounding now though the chill wind might well'[...]\n"
     ]
    }
   ],
   "source": [
    "corpus.remove_tokens(rm_pronouns=True)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all personal pronouns have now been removed from our corpus segments. We are now ready to `vectorize` our corpus, which means that we will represent it as as a large two-dimensional matrix in which each row represents one of our textual segments, and each individual feature (e.g. a function word frequency) is represented in a column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a',\n",
       " u'all',\n",
       " u'and',\n",
       " u'as',\n",
       " u'at',\n",
       " u'be',\n",
       " u'boundary',\n",
       " u'but',\n",
       " u'by',\n",
       " u'for',\n",
       " u'from',\n",
       " u'had',\n",
       " u'have',\n",
       " u'in',\n",
       " u'is',\n",
       " u'it',\n",
       " u'no',\n",
       " u'not',\n",
       " u'of',\n",
       " u'on',\n",
       " u'or',\n",
       " u'so',\n",
       " u'that',\n",
       " u'the',\n",
       " u'this',\n",
       " u'to',\n",
       " u'was',\n",
       " u'were',\n",
       " u'with',\n",
       " u'would']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vectorize(mfi=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have now included the 30 most common words in our corpus model (`mfi` stands for 'most frequent items'). These features are returned by the `vectorize()` method. Many other options are available; to extract the 50 most common character trigrams, for instance, you could run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' an',\n",
       " u' bo',\n",
       " u' in',\n",
       " u' of',\n",
       " u' th',\n",
       " u' to',\n",
       " u'and',\n",
       " u'as ',\n",
       " u'ed ',\n",
       " u'er ',\n",
       " u'he ',\n",
       " u'ing',\n",
       " u'nd ',\n",
       " u'ng ',\n",
       " u'of ',\n",
       " u'oun',\n",
       " u'ry ',\n",
       " u'the',\n",
       " u'to ',\n",
       " u'und']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vectorize(mfi=20, ngram_type='char', ngram_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more fundamental issue is the vectorization model we select. By default, the vectorizer will create a simple term-frequency model, which means that we will record the relative frequencies of our most frequent items in each text. In stylometry, however, there exist many more models. PyStyl also supports the `tf-idf` model (term frequency-inverse document frequency), which is commonly used in information retrieval to assign more weight to lower-frequency items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a',\n",
       " u'all',\n",
       " u'and',\n",
       " u'as',\n",
       " u'at',\n",
       " u'be',\n",
       " u'boundary',\n",
       " u'but',\n",
       " u'by',\n",
       " u'for',\n",
       " u'from',\n",
       " u'had',\n",
       " u'have',\n",
       " u'in',\n",
       " u'is',\n",
       " u'it',\n",
       " u'no',\n",
       " u'not',\n",
       " u'of',\n",
       " u'on',\n",
       " u'or',\n",
       " u'so',\n",
       " u'that',\n",
       " u'the',\n",
       " u'this',\n",
       " u'to',\n",
       " u'was',\n",
       " u'were',\n",
       " u'with',\n",
       " u'would']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vectorize(mfi=30, vector_space='tf_idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyStyl also supports the `std` model which underpins Burrows's famous Delta method (and which is typically also a solid model for other applications): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a',\n",
       " u'all',\n",
       " u'and',\n",
       " u'as',\n",
       " u'at',\n",
       " u'be',\n",
       " u'boundary',\n",
       " u'but',\n",
       " u'by',\n",
       " u'for',\n",
       " u'from',\n",
       " u'had',\n",
       " u'have',\n",
       " u'in',\n",
       " u'is',\n",
       " u'it',\n",
       " u'no',\n",
       " u'not',\n",
       " u'of',\n",
       " u'on',\n",
       " u'or',\n",
       " u'so',\n",
       " u'that',\n",
       " u'the',\n",
       " u'this',\n",
       " u'to',\n",
       " u'was',\n",
       " u'were',\n",
       " u'with',\n",
       " u'would']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vectorize(mfi=30, vector_space='tf_std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization is a foundational issue in stylometry, since it very much controls how our analyses 'see' texts. Luckily, the vectorize() method comes with many options to control this process. With the following options, we can for install control the proportion of segments to control in how many segments a feature should minimally occur (a procedure also known as 'culling'): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a',\n",
       " u'all',\n",
       " u'and',\n",
       " u'as',\n",
       " u'at',\n",
       " u'be',\n",
       " u'boundary',\n",
       " u'but',\n",
       " u'by',\n",
       " u'for',\n",
       " u'from',\n",
       " u'had',\n",
       " u'have',\n",
       " u'in',\n",
       " u'is',\n",
       " u'it',\n",
       " u'no',\n",
       " u'not',\n",
       " u'of',\n",
       " u'on',\n",
       " u'or',\n",
       " u'so',\n",
       " u'that',\n",
       " u'the',\n",
       " u'this',\n",
       " u'to',\n",
       " u'was',\n",
       " u'were',\n",
       " u'with',\n",
       " u'would']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vectorize(mfi=30, min_df=0.80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
